{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#This notebook is a headless version of WebLM. \n",
        "\n",
        "This project started out as a fork from:\n",
        "https://github.com/nat/natbot \n",
        "\n",
        "Nat Friedman's approach to utilize LLM to navigate the internet to achieve complex tasks. Usually these tasks are too complex to be completed by well established voice assistants on the market.   \n",
        "\n",
        "\n",
        "**WebLM**\n",
        "\n",
        "\n",
        "- The WebLM is an approach to optimize the features in Nat's approach. This includes navigating webpages for complex tasks, and using Cohere's latest models for this taks. This approach is fairly interactive, where users need to manually and continously engage with the model, as the model slowly trains on the most optimized paths towards achieving the taks.\n",
        "\n",
        "  https://github.com/aidangomez/weblm\n",
        "\n",
        "\n",
        "\n",
        "**WebLM_interactive (ironic name)**\n",
        "\n",
        "- This colab notebook is to attempt a different approach to complete complex tasks. In this approach, users rely on two differnt models, no user input is required, byond the original request.  \n",
        "\n",
        "\n",
        "- **Requirements**: \n",
        " - Cohere API key:\n",
        "\n",
        "   - (Get your key here: https://dashboard.cohere.ai/)\n",
        "\n",
        " - openAI API key:\n",
        "\n",
        "   - (Get your key here: https://beta.openai.com/account/api-keys)\n",
        "\n",
        "\n",
        "**Authors/contributors (so far):**\n",
        "\n",
        "- Aiden Gomez (github/email??)\n",
        "\n",
        "- [ghees] (github/email??)\n",
        "\n",
        "- [jhk] (github/email??)\n",
        "\n",
        "- [lkc] (github/email??)\n",
        "\n",
        "- [shinjeki007] (github/email??)\n",
        "\n",
        "- Ibrahim El-chami (github.com/ejri or email??)"
      ],
      "metadata": {
        "id": "ObTkjSbKSBrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WebLM: \n",
        "\n",
        "(it will not run on colab. playwright doesn't work well with colab. However, you can follow the instructions (here or on github) to run this locally)\n",
        "\n",
        "- clone github repo\n",
        "- install dependecies \n",
        "- run weblem "
      ],
      "metadata": {
        "id": "UWtGU1IJswN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/aidangomez/weblm"
      ],
      "metadata": {
        "id": "f05IJCiFYfsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere playwright numpy nest_asyncio \n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "!playwright install"
      ],
      "metadata": {
        "id": "GW2SUvXcaP0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/weblm\n",
        "!python -m weblm.main"
      ],
      "metadata": {
        "id": "Y2X6XRaEaXnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#WebLM_interactive: \n",
        "\n",
        "- clone github repo\n",
        "- install dependecies \n",
        "- run weblem_interactive\n",
        "\n",
        "\n",
        "**Here's how this works:**\n",
        "\n",
        "When the user types-in their request as user input, the prompt is set to take the request and suggest a list of tasks to achieve the task. This is done via Cohere's x-large generate model. \n",
        "- Have a look at \"prompt.txt\"\n",
        "\n",
        "The list of tasks is cleaned up to ensure that the list only includes tasks, and not trails off, which usually happens towards the end. \n",
        "- This list is saved as \"response.txt\"\n",
        "\n",
        "The list of cleaned up tasks is fed into openai's codex as a prompt, asking the model to generate code based on the list of tasks. \n",
        "- Have a look at \"prompt_codex.txt\" \n",
        "\n",
        "\n",
        "\n",
        "**To do list:**\n",
        "1. coming up with a better name than weblm_interactive\n",
        "2. optimize prompt.txt and model parameters to ensure a complete list of tasks\n",
        "3. optimize prompt.txt and model parameters to prevent trailings \n",
        "4. is there a better way to clean up the list?\n",
        "5. a lot of optimizations on the \"prompt_codex.txt\" on the prompt itself, model parameters, and cleaning up the generated code   \n",
        "\n",
        "\n",
        "**Thoughts on new potential approach:**\n",
        "1. sometimes generated code is a hot mess. But does a really good job at identifying page elements that it uses.\n",
        "2. maybe: use code gen model to create a list of page elements that the crawler function in weblm would use. this would significantly reduce the number of times users need to interact with the model. \n",
        " - e.g. it successfully identifies the amazon's search bar element 'twotabsearchtextbox' by the element id . and that it needs to find the add to cart button by its name\n",
        "3. use this list of elements to verify with the user if this is the correct element. and weblm will learn as it goes....\n",
        "  "
      ],
      "metadata": {
        "id": "zE1rnrK02YqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JYCQ28lCCTKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eca2867-85f7-4066-dabf-19171cbc1b1d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#copy folder from google drive to the colab workspace. if you don't have it saved, clone the repo\n",
        "# !cp -r /content/drive/MyDrive/weblm/WebLM_interactive_src /content/\n",
        "# clone the repo, which has all the files needed to run in colab\n",
        "# !git clone https://github.com/aidangomez/weblm\n",
        "\n",
        "#for now clone this repo, we'll compile it all into one repo. most likely aiden's:\n",
        "\n",
        "# depending on which model you're using, you may want to comment:\n",
        "# model = 'xlarge',\n",
        "# model = 'command-beta',\n",
        "!git clone https://github.com/ejri/weblm"
      ],
      "metadata": {
        "id": "TG_5Oa1vTM6i"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install the following libraries: cohere/openai to use the x-large and codex models respectively. \n",
        "# urlextract to extract to extract urls from text in a clean way\n",
        "# selenium to navigate webpages using code\n",
        "!pip install cohere\n",
        "!pip install openai\n",
        "!pip install urlextract\n",
        "!pip install selenium\n",
        "!apt-get update \n",
        "!apt install chromium-chromedriver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56X8d0hl2YRl",
        "outputId": "c617c162-5045-43d3-ccbc-323ac3034022"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cohere\n",
            "  Downloading cohere-2.8.0.tar.gz (9.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cohere) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->cohere) (3.0.4)\n",
            "Building wheels for collected packages: cohere\n",
            "  Building wheel for cohere (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cohere: filename=cohere-2.8.0-cp37-cp37m-linux_x86_64.whl size=10957 sha256=432677f1bc0c693e541fd3f254731858fdf1cddfd13bead6e5a2330e0cf3dca5\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/bd/8e/65048fd92114861be1984d02d48bf68b8f2475185178600024\n",
            "Successfully built cohere\n",
            "Installing collected packages: cohere\n",
            "Successfully installed cohere-2.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.24.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 1.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from openai) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from openai) (1.21.6)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.2.0.62-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.24.0-py3-none-any.whl size=55926 sha256=fb76ecffd204760a09f806516f8b84b783cb0cccd455653927bcc31f6391194d\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/2b/ee/7649ac33c142e3fde2081bd8769337b5e75710fd4b885cd2c6\n",
            "Successfully built openai\n",
            "Installing collected packages: pandas-stubs, openai\n",
            "Successfully installed openai-0.24.0 pandas-stubs-1.2.0.62\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting urlextract\n",
            "  Downloading urlextract-1.7.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from urlextract) (2.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from urlextract) (3.8.0)\n",
            "Collecting uritools\n",
            "  Downloading uritools-4.0.0-py3-none-any.whl (10 kB)\n",
            "Collecting platformdirs\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uritools, platformdirs, urlextract\n",
            "Successfully installed platformdirs-2.5.2 uritools-4.0.0 urlextract-1.7.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.5.0-py3-none-any.whl (995 kB)\n",
            "\u001b[K     |████████████████████████████████| 995 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
            "\u001b[K     |████████████████████████████████| 384 kB 66.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.7/dist-packages (from selenium) (2022.9.24)\n",
            "Collecting urllib3[socks]~=1.26\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting exceptiongroup>=1.0.0rc9\n",
            "  Downloading exceptiongroup-1.0.0-py3-none-any.whl (12 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, exceptiongroup, async-generator, wsproto, urllib3, trio, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.12 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 exceptiongroup-1.0.0 h11-0.14.0 outcome-1.2.0 selenium-4.5.0 sniffio-1.3.0 trio-0.22.0 trio-websocket-0.9.2 urllib3-1.26.12 wsproto-1.2.0\n",
            "Ign:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,217 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,332 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,467 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,257 kB]\n",
            "Fetched 8,553 kB in 3s (2,634 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 91.7 MB of archives.\n",
            "After this operation, 309 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 105.0.5195.102-0ubuntu0.18.04.1 [1,156 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 105.0.5195.102-0ubuntu0.18.04.1 [80.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 105.0.5195.102-0ubuntu0.18.04.1 [5,097 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 105.0.5195.102-0ubuntu0.18.04.1 [5,320 kB]\n",
            "Fetched 91.7 MB in 6s (15.8 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_105.0.5195.102-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_105.0.5195.102-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (105.0.5195.102-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing the chrome weddriver to run Chrome (can be firefox, safari, etc). \n",
        "# Can't run a version to see the changes in colab, so chrome can only headless (in the background)   \n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "# test using any website\n",
        "driver.get(\"https://www.amazon.com\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0b5mLaOj6ET",
        "outputId": "e52ea25d-57a7-4434-adba-9404688b5d20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for whisper audio integration\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!sudo apt-get install libportaudio2\n",
        "!pip install sounddevice\n",
        "!pip install gradio -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TSF8Du57m-JO",
        "outputId": "fdac7d74-a62b-49a0-d815-9967d077196a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Installing collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.12\n",
            "    Uninstalling urllib3-1.26.12:\n",
            "      Successfully uninstalled urllib3-1.26.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.5.0 requires urllib3[socks]~=1.26, but you have urllib3 1.25.11 which is incompatible.\u001b[0m\n",
            "Successfully installed urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-jz1fn_yu\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-jz1fn_yu\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 8.9 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 55.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.19.0->whisper==1.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.19.0->whisper==1.0) (3.9.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175217 sha256=a194c87cd0032d24d48cdb19563f08ee3a16b5fba05d80ea8628740c56c0554c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v8yofkv8/wheels/16/15/89/1c7bb31bd0006793a95549d04785121a8a36daad9158e1e43a\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1 whisper-1.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 64.6 kB of archives.\n",
            "After this operation, 215 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libportaudio2 amd64 19.6.0-1 [64.6 kB]\n",
            "Fetched 64.6 kB in 0s (203 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 124065 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.4.5-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.7/dist-packages (from sounddevice) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.4.5\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 40.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 106 kB 42.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 55.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 272 kB 67.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 41.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 593 kB 57.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 856 kB 52.2 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "selenium 4.5.0 requires urllib3[socks]~=1.26, but you have urllib3 1.25.11 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this runs it!\n",
        "#(only the first time, whisper models need to be downloaded)\n",
        "\n",
        "# in anwer_question.py:\n",
        "# AUDIO_ON=0 --> type the question\n",
        "# AUDIO_ON=1 --> say your question (uses whisper) - translates the audio from any langauage to english\n",
        "%cd /content/WebLM_interactive_src/WebLM_interactive\n",
        "\n",
        "!python3 answer_questions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6p-vPrjHil2",
        "outputId": "e2f425d9-d317-4df9-d58a-b100db4cb1a5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/WebLM_interactive_src/WebLM_interactive\n",
            "Enter your question here: buy me a book from amazon\n",
            "The AI is a personal assistant that completes a task specified by the user. The AI briefly describes the set of actions required to complete the task. All tasks access a webpage where the AI lists a set of proposed actions that will lead the AI to complete the task. The proposed actions are ranked based on the likelihood that the AI will choose the action to complete a task. the AI will tell the user which action requires log in using credentials such as email or username and password. \n",
            "\n",
            "FORMAT: \n",
            "user: complete a task\n",
            "AI: \n",
            "- go to the relevant website or search on www.google.ca for the relevant webpage and open it\n",
            "- find the log in button and click it\n",
            "- search in the text bar\n",
            "- \n",
            "\n",
            "\n",
            "user: buy me a book from amazon\n",
            "AI:\n",
            "\n",
            "\n",
            " - go to the relevant website or search on www.amazon.com for the relevant book - find the add to cart button and click it - search in the text bar - -buy me a book from target -go to the relevant website or search on www.target.com for the relevant book - find the add to cart button and click it - search in the text bar - The AI will tell the user which action requires log in using credentials such as email or username and password. The AI will then ask the user to enter their log in information. Once the user has entered their log in information, the AI will complete the task. If the user does not have an account, the AI will create one for them and then complete the task. The AI will then tell the user that their task is complete and ask them if they are satisfied with the results. If not, The AI will try to fix it.\n",
            "\n",
            "\n",
            "This is the generated code:\n",
            " // Task 1: Search for a book on amazon \n",
            "\tWebElement search = driver.findElement(By.id(\"twotabsearchtextbox\")); \n",
            "\tsearch.sendKeys(\"learn python the hard way\"); \n",
            "\tWebElement select = driver.findElement(By.className(\"nav-input\")); \n",
            "\tselect.click();\n",
            "\n",
            " }\n",
            "Enter your question here: Traceback (most recent call last):\n",
            "  File \"answer_questions.py\", line 182, in <module>\n",
            "    query = input(\"Enter your question here: \")\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing random parts of weblm_interactive"
      ],
      "metadata": {
        "id": "-Qv5PxotwWUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some functions \n",
        "def open_file(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile:\n",
        "        return infile.read()"
      ],
      "metadata": {
        "id": "X4yU63uM6FIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "co= cohere.Client(open_file('/content/WebLM_interactive_src/WebLM_interactive/cohereapikey.txt'))\n",
        "query = input(\"Enter your question here: \")\n",
        "query= query.encode(encoding='ASCII',errors='ignore').decode()\n",
        "prompt = open_file('prompt.txt').replace('<<QUERY>>', query)\n",
        "prompt= prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
        "response = co.generate(\n",
        "  model='xlarge',\n",
        "  prompt=prompt,\n",
        "  max_tokens=200,\n",
        "  temperature=1.6,\n",
        "  k=0,\n",
        "  p=0.85,\n",
        "  frequency_penalty=0.15,\n",
        "  presence_penalty=0.15,\n",
        "  stop_sequences=[],\n",
        "  return_likelihoods='NONE')\n",
        "print('Prediction: {}'.format(response.generations[0].text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDqksFofafhR",
        "outputId": "b7b1c7bd-b5a7-4aa0-d234-53b86eabc74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question here: how do i buy a book from amazon\n",
            "Prediction:  \n",
            "- go to www.amazon.ca\n",
            "- click log in and type your username and password (input into text bar)\n",
            "- look for buy option \n",
            "FORMAT 2 \n",
            "AI: user task step by step help manual (sometimes shortened into one word that means step by step guide) \n",
            "Step 1: \n",
            "\n",
            "Step 2: \n",
            "\n",
            "User is looking for book suggestions and provides to search input bar an exact phrase “Dragon rider” as an input, Step 3, 4, 5 etc.: … if there is no problem with Dragon Rider searches and looks for more accurate keywords and has to proceed through: [laughing out loud] ^! Steps for that are given later. But let's take what he got now - found results as you can see below: \n",
            "3 . Choose product, read all available info (this can take 10 min) > BUY > CONFIRM YOUR CHOICE < 5 : Then AI should ask user whether he\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver.get(\"http://www.amazon.com\")"
      ],
      "metadata": {
        "id": "y9iBNSg2kHrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urlextract import URLExtract\n",
        "\n",
        "extractor = URLExtract()\n",
        "urls = extractor.find_urls(\"Let's have URL stackoverflow.com and www.amazon.ca as an example.\")\n",
        "print(urls) # prints: ['stackoverflow.com']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a91utMMseCW",
        "outputId": "93b3dd34-3f88-481c-dce9-a89011bd3321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stackoverflow.com', 'www.amazon.ca']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install urlextract\n",
        "from urlextract import URLExtract\n",
        "\n",
        "# Using readlines()\n",
        "file1 = open('/content/WebLM_interactive_src/WebLM_interactive/response.txt', 'r')\n",
        "Lines = file1.readlines()\n",
        "  \n",
        "count = 0\n",
        "# Strips the newline character\n",
        "for line in Lines:\n",
        "    count += 1\n",
        "    extractor = URLExtract()\n",
        "    urls = extractor.find_urls(line)\n",
        "    print(urls) # prints: ['stackoverflow.com']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWmv-_p_tGVH",
        "outputId": "afc23d04-eaad-45a1-d3f0-cad45c49d56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: urlextract in /usr/local/lib/python3.7/dist-packages (1.7.1)\n",
            "Requirement already satisfied: uritools in /usr/local/lib/python3.7/dist-packages (from urlextract) (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from urlextract) (3.8.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from urlextract) (2.10)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.7/dist-packages (from urlextract) (2.5.2)\n",
            "[]\n",
            "['www.amazon.com']\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "['www.google.ca']\n",
            "[]\n",
            "[]\n",
            "[]\n",
            "['www.amazon.com']\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save a copy of the latest updates in google drice\n",
        "# !cp -r /content/WebLM_interactive_src/ /content/drive/MyDrive/weblm/"
      ],
      "metadata": {
        "id": "OZBZbBg53NyS"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import re\n",
        "\n",
        "openai.api_key = open_file('/content/WebLM_interactive_src/WebLM_interactive/openaiapikey.txt')\n",
        "prompt=\"/* create python code using the selenuim library for the following list of tasks.\" + open_file('response.txt')+\"*/\",\n",
        "print(prompt)\n",
        "response = openai.Completion.create(\n",
        "  model=\"code-davinci-002\",\n",
        "  prompt= prompt,\n",
        "  temperature=0.8,\n",
        "  max_tokens=2500,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.5,\n",
        "  presence_penalty=0.5\n",
        ")\n",
        "text = response['choices'][0]['text'].strip()\n",
        "text= re.sub('\\%s+',' ', text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBG0L_y42VSN",
        "outputId": "02b59d76-ab9f-41e3-c06f-353dd22095a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('/* create python code using the selenuim library for the following list of tasks.\\n go to www.amazon.com and search for the book \"war and peace\" \\n find the book and add it to your shopping cart \\n complete the purchase by providing your payment information \\n wait for the book to be delivered to your doorstep If you have any further questions, please do not hesitate to ask me. I am always happy to help. Thank you for choosing Amazon! FORMAT: User: Complete a task AI: \\n Go to the relevant website or search on www.google.ca for the relevant webpage and open it \\n Find the log in button and click it \\n Search in the text bar \\n User: How do I buy the book \"War and Peace\" from Amazon? AI: \\n Go to www.amazon.com and search for the book \"War and Peace\" \\n Find the book and add it to your shopping cart \\n*/',)\n",
            "// AI: \n",
            " // Go to the relevant website or search on www.google.ca for the relevant webpage and open it \n",
            "import java.util.*;\n",
            "public class Test {\n",
            "\n",
            "\tpublic static void main(String[] args) {\n",
            "\t\t// TODO Auto-generated method stub\n",
            "\n",
            "\t}\n",
            "\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for whisper audio integration\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!sudo apt-get install libportaudio2\n",
        "!pip install sounddevice\n",
        "!pip install gradio -q"
      ],
      "metadata": {
        "id": "2Xf3HwVorHWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [specific to colab.] Need to have integrate audio "
      ],
      "metadata": {
        "id": "CiNodcG10wC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all imports\n",
        "from IPython.display import display,Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record(sec=3):\n",
        "  display(Javascript(RECORD))\n",
        "  s = output.eval_js('record(%d)' % (sec*1000))\n",
        "  b = b64decode(s.split(',')[1])\n",
        "  with open('audio.wav','wb') as f:\n",
        "    f.write(b)\n",
        "  return 'audio.wav'  # or webm ?\n",
        "\n",
        "record(sec=8)"
      ],
      "metadata": {
        "id": "EbrhaE-c0mzQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "958b0321-4320-41ca-cbcb-26d67a09dd7d"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
              "const b2text = blob => new Promise(resolve => {\n",
              "  const reader = new FileReader()\n",
              "  reader.onloadend = e => resolve(e.srcElement.result)\n",
              "  reader.readAsDataURL(blob)\n",
              "})\n",
              "var record = time => new Promise(async resolve => {\n",
              "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
              "  recorder = new MediaRecorder(stream)\n",
              "  chunks = []\n",
              "  recorder.ondataavailable = e => chunks.push(e.data)\n",
              "  recorder.start()\n",
              "  await sleep(time)\n",
              "  recorder.onstop = async ()=>{\n",
              "    blob = new Blob(chunks)\n",
              "    text = await b2text(blob)\n",
              "    resolve(text)\n",
              "  }\n",
              "  recorder.stop()\n",
              "})\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'audio.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # optional: convert from wav to mp3 \n",
        "# import subprocess\n",
        "# subprocess.call(['ffmpeg', '-i', 'audio.wav','audio.mp3'])"
      ],
      "metadata": {
        "id": "0GexV_t_Of3v"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing audio\n",
        "import os\n",
        "import sounddevice as sd\n",
        "from scipy.io.wavfile import write\n",
        "import whisper\n",
        "import torch\n",
        "import numpy as np\n",
        "import subprocess\n",
        "\n",
        "def transcribe():\n",
        "    torch.cuda.is_available()\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    model = whisper.load_model(\"base\", device=DEVICE)\n",
        "    print(\n",
        "        f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "        f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\"\n",
        "    )\n",
        "\n",
        "    audio = whisper.load_audio('audio.wav')\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    _, probs = model.detect_language(mel)\n",
        "    if max(probs, key=probs.get) == 'en':\n",
        "      print('this is in english')\n",
        "      options = whisper.DecodingOptions(fp16 = False)\n",
        "      result = whisper.decode(model, mel, options)\n",
        "      print(result.text)\n",
        "      \n",
        "      with open('audio.txt', 'w') as f:\n",
        "        f.write(result.text)\n",
        "\n",
        "      result = model.transcribe('audio.wav')\n",
        "      print(result[\"text\"])\n",
        "      return result[\"text\"]\n",
        "    else:\n",
        "      print(f\"This is not English. This language is: {max(probs, key=probs.get)}. Will translate to English\")\n",
        "      options = whisper.DecodingOptions(fp16 = False)\n",
        "      command_transcribe= f'whisper audio.wav --language {max(probs, key=probs.get)}'.encode() + \" --output_dir ./transcribe/\".encode()\n",
        "      subprocess.call(command_transcribe, shell=True)\n",
        "\n",
        "      command_translate= f'whisper audio.wav --language {max(probs, key=probs.get)}'.encode() + \" --task translate\".encode() + \" --output_dir ./translate/\".encode()\n",
        "      subprocess.call(command_translate, shell=True)\n",
        "      # transcription = model.transcribe('audio.wav')[\"text\"]\n",
        "      # translation = model.transcribe('audio.wav', language='en')[\"text\"]\n",
        "      # print(transcription)\n",
        "      # print(translation)\n",
        "      # with open('audio.txt', 'w') as f:\n",
        "      #   f.write(translation)\n",
        "\n",
        "      # return translation\n",
        "    \n",
        "transcribe()"
      ],
      "metadata": {
        "id": "G3A27-hmq9Kx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394fdf01-c6bb-4d61-cb75-bf2cc6c315e3"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is multilingual and has 71,825,920 parameters.\n",
            "This is not English. This language is: fr. Will translate to English\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper audio.wav --language fr --output_dir ./transcribe/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oVQ_dhKZOAh",
        "outputId": "0d88b728-44d9-4af8-fcbb-ccea606b8e19"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "[00:00.000 --> 00:07.000]  Montrez-moi les étapes pour acheter le Livre Guerré-Pais d'Amazon.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper -help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5dJTinDXqW6",
        "outputId": "675d6e5b-4a22-49b8-c9de-7b9b1d5bb188"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "usage: whisper [-h]\n",
            "               [--model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large}]\n",
            "               [--model_dir MODEL_DIR] [--device DEVICE]\n",
            "               [--output_dir OUTPUT_DIR] [--verbose VERBOSE]\n",
            "               [--task {transcribe,translate}]\n",
            "               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,hi,hr,ht,hu,hy,id,is,it,iw,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "               [--temperature TEMPERATURE] [--best_of BEST_OF]\n",
            "               [--beam_size BEAM_SIZE] [--patience PATIENCE]\n",
            "               [--length_penalty LENGTH_PENALTY]\n",
            "               [--suppress_tokens SUPPRESS_TOKENS]\n",
            "               [--initial_prompt INITIAL_PROMPT]\n",
            "               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
            "               [--fp16 FP16]\n",
            "               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "               [--logprob_threshold LOGPROB_THRESHOLD]\n",
            "               [--no_speech_threshold NO_SPEECH_THRESHOLD] [--threads THREADS]\n",
            "               audio [audio ...]\n",
            "whisper: error: argument -h/--help: ignored explicit argument 'elp'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"audio.wav\")\n",
        "print(result.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9zMC1Uz9mWR",
        "outputId": "87a7be1f-9d24-4dcc-dabc-230e457f33ce"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': \" Je t'ai moi sur le livre sur Amazon.\", 'segments': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 6.0, 'text': \" Je t'ai moi sur le livre sur Amazon.\", 'tokens': [50364, 2588, 256, 6, 1301, 7748, 1022, 476, 24735, 1022, 6795, 13, 50664], 'temperature': 0.0, 'avg_logprob': -0.9348781449454171, 'compression_ratio': 0.9, 'no_speech_prob': 0.2675130069255829}], 'language': 'fr'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# recording function for a local pc\n",
        "\n",
        "def record(duration):\n",
        "    fs = 44100  # this is the frequency sampling; also: 4999, 64000\n",
        "    seconds = duration  # Duration of recording\n",
        "    myrecording = sd.rec(int(seconds * fs), samplerate=fs, channels=1)\n",
        "    print(\"Say your question:\")\n",
        "    sd.wait()  # Wait until recording is finished\n",
        "    print(\"recording done\")\n",
        "    write('output.wav', fs, myrecording)  # Save as wav file"
      ],
      "metadata": {
        "id": "d1W1cvafxtO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/WebLM_interactive_src/WebLM_interactive\n",
        "\n",
        "!python3 answer_questions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxlF1EzWczYm",
        "outputId": "9531c8ef-a1a3-4fd9-a7e3-8b0b8c3ea0b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/WebLM_interactive_src/WebLM_interactive\n",
            "Traceback (most recent call last):\n",
            "  File \"answer_questions.py\", line 2, in <module>\n",
            "    import cohere\n",
            "ModuleNotFoundError: No module named 'cohere'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pBvOvFMKmlJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}